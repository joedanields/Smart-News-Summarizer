from scraper import NewsExtractor
from summarizer import SmartSummarizer
import time

def test_complete_pipeline():
    """Test the complete scraper + summarizer pipeline"""
    print("ğŸ”¥ Testing Complete AI News Summarizer Pipeline")
    print("=" * 70)
    
    # Initialize components
    extractor = NewsExtractor()
    summarizer = SmartSummarizer()
    
    # Test with your successful Times of India URL
    test_url = "https://timesofindia.indiatimes.com/technology/tech-news/what-have-we-done-sam-altman-says-i-feel-useless-compares-chatgpt-5s-power-to-the-manhattan-project/articleshow/123112813.cms"
    
    print(f"ğŸ“° Extracting article from: Times of India")
    print("ğŸ”„ Step 1: Web scraping...")
    
    # Extract article
    article_data = extractor.extract_article(test_url)
    
    if 'error' in article_data:
        print(f"âŒ Extraction failed: {article_data['error']}")
        return
    
    print(f"âœ… Article extracted successfully!")
    print(f"ğŸ“ Title: {article_data['title']}")
    print(f"ğŸ“Š Words: {article_data['word_count']:,}")
    print(f"ğŸ¯ Quality: {article_data['quality_score']}/100")
    
    print("\nğŸ¤– Step 2: AI Summarization...")
    
    # Generate summaries
    results = summarizer.batch_summarize(article_data['text'])
    
    print(f"\nğŸ“‹ COMPLETE PIPELINE RESULTS:")
    print("=" * 70)
    print(f"ğŸŒ Source: Times of India - Sam Altman/ChatGPT-5 Article")
    print(f"ğŸ“… Extracted: {article_data['extracted_at'].strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"âš™ï¸  Extraction Method: {article_data['extraction_method']}")
    
    for length, result in results.items():
        if result['status'] == 'success':
            print(f"\nğŸ“ {length.upper()} SUMMARY:")
            print(f"   ğŸ“Š {result['summary_words']} words ({result['compression_ratio']}% compression)")
            print(f"   â±ï¸  Generated in: {result['processing_time']}s")
            print(f"   ğŸ“„ Content: {result['summary']}")
            print(f"   ğŸ“ Character Length: {len(result['summary'])}")
    # Extract insights
    keywords = summarizer.extract_keywords(article_data['text'])
    sentiment = summarizer.analyze_content_sentiment(article_data['text'])
    
    print(f"\nğŸ” KEY TOPICS: {', '.join(keywords[:6])}")
    print(f"ğŸ’­ SENTIMENT: {sentiment}")
    print(f"ğŸ“ˆ READING TIME SAVED: ~{article_data['word_count']//200 - 1} minutes")
    
    print(f"\nğŸ¯ AICTE DEMO READINESS: âœ… EXCELLENT")
    print("   â€¢ High-quality content extraction")
    print("   â€¢ Multiple summary lengths working")
    print("   â€¢ Fast processing times")
    print("   â€¢ Rich metadata and insights")

if __name__ == "__main__":
    test_complete_pipeline()
